{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b366fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b923c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CARDS = 3\n",
    "NUM_DETECTORS = 60\n",
    "NUM_TIMESTEPS = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d8fff",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32405660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, num_cards, num_detectors, num_timesteps):\n",
    "        self.num_cards = num_cards\n",
    "        self.num_detectors = num_detectors\n",
    "        self.num_timesteps = num_timesteps\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.rand(self.num_cards, self.num_detectors, self.num_timesteps), torch.rand(self.num_detectors, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GeoDataset(NUM_CARDS, NUM_DETECTORS, NUM_TIMESTEPS)\n",
    "dataloader = DataLoader(dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloader))[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67a1bb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4a36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXtBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_channels, norm_groups=32, expansion_rate=4):\n",
    "        super().__init__()\n",
    "        self.dw_conv = nn.Conv2d(num_channels, num_channels, kernel_size=7, padding=3, groups=num_channels)\n",
    "        self.group_norm = nn.GroupNorm(norm_groups, num_channels)\n",
    "        hidden_channels = expansion_rate * num_channels\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, hidden_channels, kernel_size=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(hidden_channels, num_channels, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.dw_conv(x)\n",
    "        out = self.group_norm(out)\n",
    "        out = self.feed_forward(out)\n",
    "        x = x + out\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet1D(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_channels=256,\n",
    "        num_channels=3,\n",
    "        groups=32,\n",
    "        expansion_rate=4,\n",
    "        dim_mult=(1, 2, 4, 8),\n",
    "        num_blocks=(3, 3, 3, 3),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, model_channels, kernel_size=(1, 4), stride=(1, 4)),\n",
    "            nn.GroupNorm(groups, model_channels)\n",
    "        )\n",
    "        \n",
    "        hidden_dims = list(map(lambda mult: model_channels * mult, (1,) + dim_mult))\n",
    "        in_out_dims = list(zip(hidden_dims[:-1], hidden_dims[1:]))\n",
    "        self.resnext_blocks = nn.Sequential(*[\n",
    "            nn.Sequential(\n",
    "                *[ResNeXtBlock(in_dim, groups, expansion_rate) for _ in range(num_block)],\n",
    "                nn.GroupNorm(groups, in_dim),\n",
    "                nn.Conv2d(in_dim, out_dim, kernel_size=(1, 2), stride=(1, 2))\n",
    "            ) for (in_dim, out_dim), num_block in zip(in_out_dims, num_blocks)\n",
    "        ])\n",
    "        \n",
    "        self.out_layer = nn.Linear(in_out_dims[-1][-1], 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.resnext_blocks(x)\n",
    "        x = x.mean(-1).transpose(-1, -2)\n",
    "        x = self.out_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc518c0f",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoTrainer(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, num_channels):\n",
    "        super().__init__()\n",
    "        self.model = ResNet1D(num_channels=NUM_CARDS)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=2e-4)\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "#             optimizer, start_factor=0.0002, end_factor=1.0, total_iters=5000\n",
    "#         )\n",
    "        return [optimizer]\n",
    "    \n",
    "    def model_step(self, batch, stage):\n",
    "        img, target_timesteps = batch\n",
    "        pred_timesteps = self.model(img)\n",
    "        loss = self.loss(pred_timesteps, target_timesteps)\n",
    "        self.log(f'{stage}_loss', loss.detach().cpu().item())\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.model_step(batch, 'train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.model_step(batch, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = pl.loggers.TensorBoardLogger(name='test', save_dir=\"./tb_logs\", default_hp_metric=False)\n",
    "callbacks = [\n",
    "    pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=\"./saved_models/test\", filename=\"{step}\", monitor=\"train_loss\", mode=\"min\",\n",
    "        save_top_k=-1, every_n_train_steps=5000\n",
    "    )\n",
    "]\n",
    "trainer = pl.Trainer(\n",
    "    logger=tb_logger,\n",
    "#     callbacks=callbacks,\n",
    "    gpus=1,\n",
    "    log_every_n_steps=5,\n",
    "    max_steps=500000,\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm=\"value\"\n",
    ")\n",
    "model = GeoTrainer(NUM_CARDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571cb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
